% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/api_utils.R
\name{send_to_llm}
\alias{send_to_llm}
\title{Send a prompt to a connected LLM}
\usage{
send_to_llm(
  connection,
  prompt,
  data = NULL,
  max_rows = 50,
  max_cols = 20,
  llm_params = list(),
  ...
)
}
\arguments{
\item{connection}{An LLM connection object (e.g., from \code{create_llm_connection}).}

\item{prompt}{The text prompt to send to the LLM.}

\item{data}{Optional dataset to include in the prompt (if supported and small).}

\item{max_rows}{Max rows for including full data.}

\item{max_cols}{Max columns for including full data.}

\item{llm_params}{A list of provider-specific parameters (e.g., temperature, max_tokens).}

\item{...}{Additional arguments specific to the provider's send method.}
}
\value{
The LLM's response text.
}
\description{
Sends a text prompt to a connected LLM and retrieves the response. This is an S3 generic function
with specific implementations for each supported LLM provider. It can optionally include a dataset
in the prompt if it's small enough.
}
\examples{
\dontrun{
# Create a connection
conn <- create_llm_connection(
  provider = "gemini",
  api_key = "your_gemini_api_key",
  model = "gemini-1.0-pro"
)

# Send a simple prompt
response <- send_to_llm(
  connection = conn,
  prompt = "Suggest three statistical methods for time series analysis."
)

# Send a prompt with a dataset
response <- send_to_llm(
  connection = conn,
  prompt = "How would you analyze this dataset to understand the relationship between horsepower
  and mpg?",
  data = mtcars,
  llm_params = list(temperature = 0.2, maxOutputTokens = 2000)
)
}
}
